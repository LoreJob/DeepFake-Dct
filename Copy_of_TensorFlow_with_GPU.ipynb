{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LoreJob/DeepFake-Dct/blob/main/Copy_of_TensorFlow_with_GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMce8muBqXQP"
      },
      "source": [
        "# Tensorflow with GPU\n",
        "\n",
        "This notebook provides an introduction to computing on a [GPU](https://cloud.google.com/gpu) in Colab. In this notebook you will connect to a GPU, and then run some basic TensorFlow operations on both the CPU and a GPU, observing the speedup provided by using the GPU.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM_8ELnJq_wd"
      },
      "source": [
        "## Enabling and testing the GPU\n",
        "\n",
        "First, you'll need to enable GPUs for the notebook:\n",
        "\n",
        "- Navigate to Editâ†’Notebook Settings\n",
        "- select GPU from the Hardware Accelerator drop-down\n",
        "\n",
        "Next, we'll confirm that we can connect to the GPU with tensorflow:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "sXnDmXR7RDr2",
        "outputId": "a03c8954-60f9-41a3-a175-287bccb3ac8f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SystemError",
          "evalue": "GPU device not found",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-d1680108c58e>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'/device:GPU:0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mSystemError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU device not found'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Found GPU at: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemError\u001b[0m: GPU device not found"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3fE7KmKRDsH"
      },
      "source": [
        "## Observe TensorFlow speedup on GPU relative to CPU\n",
        "\n",
        "This example constructs a typical convolutional neural network layer over a\n",
        "random image and manually places the resulting ops on either the CPU or the GPU\n",
        "to compare execution speed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "Y04m-jvKRDsJ",
        "outputId": "3162bdfe-fdfd-428c-8016-312c21949a20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "This error most likely means that this notebook is not configured to use a GPU.  Change this in Notebook Settings via the command palette (cmd/ctrl-shift-P) or the Edit menu.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemError",
          "evalue": "GPU device not found",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-38fe9b77e24a>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0;34m'configured to use a GPU.  Change this in Notebook Settings via the '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mSystemError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU device not found'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemError\u001b[0m: GPU device not found"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')\n",
        "\n",
        "def cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "    return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "def gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "    return tf.math.reduce_sum(net_gpu)\n",
        "\n",
        "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
        "cpu()\n",
        "gpu()\n",
        "\n",
        "# Run the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy"
      ],
      "metadata": {
        "id": "GGdFw_avd6k8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "metadata": {
        "id": "fpFCFcx5d8qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/LoreJob/DeepFake-Dct.git"
      ],
      "metadata": {
        "id": "oC24b5WJd_ci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/content/DeepFake-Dct/dataset big\""
      ],
      "metadata": {
        "id": "kZT-YoOdgNCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(data_dir)"
      ],
      "metadata": {
        "id": "ZpKcai44gmcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len( os.listdir((os.path.join(data_dir,'Train','Real')))))\n",
        "print(len( os.listdir((os.path.join(data_dir,'Train','Fake')))))"
      ],
      "metadata": {
        "id": "zJMt17HxgtvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image_class in os.listdir((os.path.join(data_dir,'Train','Real'))):\n",
        "  print(image_class)\n",
        "  break"
      ],
      "metadata": {
        "id": "ypuQ5kNbgutB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(os.path.join(data_dir,'Train','Real','real_0.jpg'))"
      ],
      "metadata": {
        "id": "lhTYku-VgxJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(img)"
      ],
      "metadata": {
        "id": "6AK6akjXgzJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape"
      ],
      "metadata": {
        "id": "TC_taSHig1Z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"
      ],
      "metadata": {
        "id": "cdPIp1UWg6Ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_direct = \"/content/DeepFake-Dct/dataset big/Train\"\n",
        "data = tf.keras.utils.image_dataset_from_directory(data_direct)\n",
        "\n",
        "data_iterator = data.as_numpy_iterator()\n",
        "\n",
        "batch = data_iterator.next()\n",
        "\n",
        "print(len(batch))"
      ],
      "metadata": {
        "id": "oDdYWqzSiDFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch[0].shape"
      ],
      "metadata": {
        "id": "Bj95RO_CiUS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch[1]"
      ],
      "metadata": {
        "id": "OgcIYE3ViPAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(ncols = 4, figsize = (20,20))\n",
        "\n",
        "for idx, img in enumerate(batch[0][:4]):\n",
        "    ax[idx].imshow(img.astype(int))\n",
        "    ax[idx].title.set_text(batch[1][idx])"
      ],
      "metadata": {
        "id": "g7OJQ66FiRy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data = data.map(lambda x,y: (x/255,y))"
      ],
      "metadata": {
        "id": "WP4QnxGjiXL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scaled_iterator = data.as_numpy_iterator()\n",
        "# scaled_iterator"
      ],
      "metadata": {
        "id": "Vow6tZ8piZ2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# batch = scaled_iterator.next()"
      ],
      "metadata": {
        "id": "uypjQUlbibi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#len(data)"
      ],
      "metadata": {
        "id": "47SUTTAEiciE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_size = int(len(data)*.7)\n",
        "# val_size = int(len(data)*.2)\n",
        "# test_size = int(len(data)*.1)\n",
        "\n",
        "# train_size + val_size + test_size"
      ],
      "metadata": {
        "id": "l1K00LeHiek8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train = data.take(train_size)\n",
        "# val = data.skip(train_size).take(val_size)\n",
        "# test = data.skip(train_size + val_size).take(test_size)"
      ],
      "metadata": {
        "id": "kh1xmGXKigk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_direct,\n",
        "    image_size=(256, 256),\n",
        "    batch_size=32,\n",
        "    seed=123\n",
        ")"
      ],
      "metadata": {
        "id": "8_jfpSEIouam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_data = tf.keras.utils.image_dataset_from_directory(\n",
        "    \"/content/DeepFake-Dct/dataset big/Validation\",\n",
        "    image_size=(256, 256),\n",
        "    batch_size=32,\n",
        "    seed=123\n",
        ")"
      ],
      "metadata": {
        "id": "oHmRCgyvpCXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "data = data.prefetch(buffer_size=AUTOTUNE)\n",
        "val_data = val_data.prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "bKf3sjVXpc6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "pdKYHo41jBg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential([\n",
        "    layers.Rescaling(1./255, input_shape=(256, 256, 3)),  # Rescaling layer\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001\n",
        ")),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.25),  # Dropout layer with 25% rate\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001\n",
        ")),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.25),  # Dropout layer with 25% rate\n",
        "    layers.Conv2D(128, (3, 3), activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.001\n",
        ")),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.001\n",
        ")),\n",
        "    layers.Dropout(0.5),  # Dropout layer with 50% rate\n",
        "    layers.Dense(1, activation='sigmoid')  # Assuming binary classification\n",
        "])"
      ],
      "metadata": {
        "id": "892OK7R2qedr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "# tf.losses.BinaryCrossentropy()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    validation_data=val_data,\n",
        "    epochs=10,\n",
        "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
        ")"
      ],
      "metadata": {
        "id": "4PYWivc0p-5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = tf.keras.utils.image_dataset_from_directory(\n",
        "    \"/content/DeepFake-Dct/dataset big/Test\",\n",
        "    image_size=(256, 256),  # Adjust size based on your needs\n",
        "    batch_size=32,          # Adjust batch size based on your memory\n",
        "    seed=123                # Seed for reproducibility\n",
        ")"
      ],
      "metadata": {
        "id": "wvz5-Xzrj_Xk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "test_data = test_data.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "loss, accuracy = model.evaluate(test_data)\n",
        "\n",
        "print(f\"Test Loss: {loss}\")\n",
        "print(f\"Test Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "3XCYa_507ufx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "class_labels = ['Real', 'Fake']\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.set(font_scale=1.2)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            annot_kws={'size': 14}, xticklabels=class_labels, yticklabels=class_labels)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CHDwDa_nkIm5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}