{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LoreJob/DeepFake-Dct/blob/main/CNN_for_DeepFake_Detection_in_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knObUu4w4crU"
      },
      "source": [
        "#CNN for DeepFake Detection\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMce8muBqXQP"
      },
      "source": [
        "# Tensorflow with GPU\n",
        "\n",
        "This notebook provides an introduction to computing on a [GPU](https://cloud.google.com/gpu) in Colab. In this notebook you will connect to a GPU, and then run some basic TensorFlow operations on both the CPU and a GPU, observing the speedup provided by using the GPU.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM_8ELnJq_wd"
      },
      "source": [
        "## Enabling and testing the GPU\n",
        "\n",
        "First, you'll need to enable GPUs for the notebook:\n",
        "\n",
        "- Navigate to Ram/Disk on the upper-left part of the colab â†’ Additional Connection Options\n",
        "- select GPU T4 from the Hardware Accelerator drop-down (You have just 1 hour of using)\n",
        "\n",
        "Next, we'll confirm that we can connect to the GPU with tensorflow:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXnDmXR7RDr2",
        "outputId": "d0476431-97e6-4bee-c5ef-e60f622f76e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3fE7KmKRDsH"
      },
      "source": [
        "## Observe TensorFlow speedup on GPU relative to CPU\n",
        "\n",
        "This example constructs a typical convolutional neural network layer over a\n",
        "random image and manually places the resulting ops on either the CPU or the GPU\n",
        "to compare execution speed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y04m-jvKRDsJ",
        "outputId": "8cfcaa14-fbc5-49b5-aa40-224c6d87aeb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
            "CPU (s):\n",
            "7.214328854999998\n",
            "GPU (s):\n",
            "0.10292108700001279\n",
            "GPU speedup over CPU: 70x\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')\n",
        "\n",
        "def cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "    return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "def gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "    return tf.math.reduce_sum(net_gpu)\n",
        "\n",
        "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
        "cpu()\n",
        "gpu()\n",
        "\n",
        "# Run the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpFCFcx5d8qb",
        "outputId": "181a822f-7797-496a-cf09-f2e6bc72f429"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEf1Ql815LY7"
      },
      "source": [
        "## Packages\n",
        "As the title says, we are using the tensorflow package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GGdFw_avd6k8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Hr2gRHq5PTU"
      },
      "source": [
        "## Importing the dataset\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Height and width of which video frame (you can also do resizing)\n",
        "HEIGHT, WIDTH = 256, 256\n",
        "\n",
        "# Number of frames of a video that will be fed to the model as one sequence\n",
        "N_FRAMES = 20\n",
        "\n",
        "# Dataset dir\n",
        "DATABASE_DIR = \"Video Dataset Small\"\n",
        "\n",
        "# Classes\n",
        "CLASSES = [\"Real\", \"Fake\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating the frame extractor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def frames_extraction(video_path):\n",
        "    frames_list = []\n",
        "\n",
        "    #Reading the video\n",
        "    video_reader = cv2.VideoCapture(Dataset_dir)\n",
        "\n",
        "    #Getting total number of frames\n",
        "    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    #Selecting only the wanted amount of frames\n",
        "    skip_frames_window = max(int(video_frames_count/N_FRAMES), 1)\n",
        "\n",
        "    #Looping to the selected frames\n",
        "    for frame_counter in range(N_FRAMES):\n",
        "        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
        "        \n",
        "        #reading the frames\n",
        "        success, frame = video_reader.read()\n",
        "        #breaking if the read is not successfull\n",
        "        if not success:\n",
        "            break\n",
        "        \n",
        "        #setting the shape and normalizing the frame (each frame should have a value between 0-1)\n",
        "        resized_frame = cv2.resize(frame, (HEIGHT, WIDTH))\n",
        "        normalized_frame = resized_frame / 255\n",
        "\n",
        "        frames_list.append(normalized_frame)\n",
        "\n",
        "    video_reader.release()\n",
        "    return frames_list\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating the dataset creator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loading videos from folder\n",
        "def load_videos_from_folder(folder, label):\n",
        "    videos = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(folder):\n",
        "        video_path = os.path.join(folder, filename)\n",
        "        frames = frames_extraction(video_path)\n",
        "        if len(frames) == N_FRAMES:\n",
        "            videos.append(frames)\n",
        "            labels.append(label)\n",
        "    return videos, labels\n",
        "\n",
        "# Creating the dataset\n",
        "def create_tf_dataset(video_list, label_list):\n",
        "    video_tensors = [tf.convert_to_tensor(video, dtype=tf.float32) for video in video_list]\n",
        "    label_tensors = [tf.convert_to_tensor(label, dtype=tf.int32) for label in label_list]\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((video_tensors, label_tensors))\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loading Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define paths\n",
        "fake_train_dir = os.path.join(DATABASE_DIR, 'fake', 'train')\n",
        "fake_test_dir = os.path.join(DATABASE_DIR, 'fake', 'test')\n",
        "fake_val_dir = os.path.join(DATABASE_DIR, 'fake', 'validation')\n",
        "real_train_dir = os.path.join(DATABASE_DIR, 'real', 'train')\n",
        "real_test_dir = os.path.join(DATABASE_DIR, 'real', 'test')\n",
        "real_val_dir = os.path.join(DATABASE_DIR, 'real', 'validation')\n",
        "\n",
        "# Load videos\n",
        "fake_train_videos, fake_train_labels = load_videos_from_folder(fake_train_dir, label=1)\n",
        "fake_test_videos, fake_test_labels = load_videos_from_folder(fake_test_dir, label=1)\n",
        "fake_val_videos, fake_val_labels = load_videos_from_folder(fake_val_dir, label=1)\n",
        "real_train_videos, real_train_labels = load_videos_from_folder(real_train_dir, label=0)\n",
        "real_test_videos, real_test_labels = load_videos_from_folder(real_test_dir, label=0)\n",
        "real_val_videos, real_val_labels = load_videos_from_folder(real_val_dir, label=0)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
