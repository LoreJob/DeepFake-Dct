{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LoreJob/DeepFake-Dct/blob/main/CNN_for_DeepFake_Detection_in_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knObUu4w4crU"
      },
      "source": [
        "# CNN+LSTM for DeepFake Detection in videos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM_8ELnJq_wd"
      },
      "source": [
        "## Enabling and testing the GPU\n",
        "\n",
        "First, you'll need to enable GPUs for the notebook:\n",
        "\n",
        "- Navigate to Ram/Disk on the upper-left part of the colab â†’ Additional Connection Options\n",
        "- select GPU T4 from the Hardware Accelerator drop-down (You have just 1 hour of using)\n",
        "\n",
        "Next, we'll confirm that we can connect to the GPU with tensorflow:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXnDmXR7RDr2",
        "outputId": "d0476431-97e6-4bee-c5ef-e60f622f76e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3fE7KmKRDsH"
      },
      "source": [
        "## Observe TensorFlow speedup on GPU relative to CPU\n",
        "\n",
        "This example constructs a typical convolutional neural network layer over a\n",
        "random image and manually places the resulting ops on either the CPU or the GPU\n",
        "to compare execution speed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y04m-jvKRDsJ",
        "outputId": "8cfcaa14-fbc5-49b5-aa40-224c6d87aeb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
            "CPU (s):\n",
            "7.214328854999998\n",
            "GPU (s):\n",
            "0.10292108700001279\n",
            "GPU speedup over CPU: 70x\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')\n",
        "\n",
        "def cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "    return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "def gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "    return tf.math.reduce_sum(net_gpu)\n",
        "\n",
        "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
        "cpu()\n",
        "gpu()\n",
        "\n",
        "# Run the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpFCFcx5d8qb",
        "outputId": "181a822f-7797-496a-cf09-f2e6bc72f429"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEf1Ql815LY7"
      },
      "source": [
        "## Packages\n",
        "As the title says, we are using the tensorflow package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GGdFw_avd6k8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Hr2gRHq5PTU"
      },
      "source": [
        "## Importing the dataset\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "HEIGHT, WIDTH = 256, 256\n",
        "N_FRAMES = 20  # Number of frames of a video that will be fed to the model as one sequence\n",
        "DATASET_DIR = \"Video Dataset Small\"\n",
        "CLASSES = [\"fake\", \"real\"]\n",
        "BATCH_SIZE = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating the frame extractor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def frames_extraction(video_path):\n",
        "    frames_list = []\n",
        "\n",
        "    #Reading the video\n",
        "    video_reader = cv2.VideoCapture(video_path)\n",
        "\n",
        "    #Getting total number of frames\n",
        "    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    #Selecting only the wanted amount of frames\n",
        "    skip_frames_window = max(int(video_frames_count/N_FRAMES), 1)\n",
        "\n",
        "    #Looping to the selected frames\n",
        "    for frame_counter in range(N_FRAMES):\n",
        "        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
        "        \n",
        "        #reading the frames\n",
        "        success, frame = video_reader.read()\n",
        "        #breaking if the read is not successfull\n",
        "        if not success:\n",
        "            break\n",
        "        \n",
        "        #setting the shape and normalizing the frame (each frame should have a value between 0-1)\n",
        "        resized_frame = cv2.resize(frame, (HEIGHT, WIDTH))\n",
        "        normalized_frame = resized_frame / 255\n",
        "\n",
        "        frames_list.append(normalized_frame)\n",
        "\n",
        "    video_reader.release()\n",
        "    return frames_list\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating the dataset creator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loading videos from folder\n",
        "def create_dataset(split):\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    for class_idx, class_name in enumerate(CLASSES):\n",
        "        print(f'Extracting data of: {split}\\\\{class_name}')\n",
        "\n",
        "        file_list = os.listdir(os.path.join(DATASET_DIR, split, class_name))\n",
        "\n",
        "        for file_name in file_list:\n",
        "            video_file_path = os.path.join(DATASET_DIR, split, class_name, file_name)\n",
        "            frames = frames_extraction(video_file_path)\n",
        "\n",
        "            if len(frames) == N_FRAMES:\n",
        "\n",
        "                # Append the data to their repective lists.\n",
        "                features.append(frames)\n",
        "                labels.append(class_idx)\n",
        "\n",
        "    features = np.asarray(features)\n",
        "    labels = np.array(labels)  \n",
        "\n",
        "    return features, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loading Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data of: Train\\fake\n"
          ]
        }
      ],
      "source": [
        "# Create train, validation, and test datasets\n",
        "X_train, y_train = create_dataset(split = \"Train\")\n",
        "X_val, y_val = create_dataset(DATASET_DIR, CLASSES, split='Val')\n",
        "X_test, y_test = create_dataset(DATASET_DIR, CLASSES, split='Test')\n",
        "\n",
        "# Normalize y labels to be categorical\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=len(CLASSES))\n",
        "y_val = tf.keras.utils.to_categorical(y_val, num_classes=len(CLASSES))\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=len(CLASSES))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Shuffle datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(len(X_train))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val)).shuffle(len(X_val))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "\n",
        "# Batch datasets\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "# Prefetch for Efficiency\n",
        "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "val_dataset = val_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
