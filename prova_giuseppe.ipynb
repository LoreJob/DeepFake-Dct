{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will try to make a network that classifies images as fake or real.\n",
    "\n",
    "I will use pytorch because it's the library that I have the most experience with.\n",
    "\n",
    "The train / validation / test split I will use is the one already present in the repo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# global variables\n",
    "\n",
    "# binary classification threshold\n",
    "threshold = 0.5\n",
    "\n",
    "on_gpu = True\n",
    "\n",
    "batch_size = 128\n",
    "num_epochs = 10\n",
    "p_dropout = 0.2\n",
    "\n",
    "#SGD params\n",
    "start_lr = 1e-1\n",
    "momentum = 0.3\n",
    "\n",
    "#LR scheduler params\n",
    "start_factor= 1\n",
    "end_factor= .0001 \n",
    "total_iters= 8\n",
    "\n",
    "\n",
    "if on_gpu:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Using {device} device\")\n",
    "else:\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will start by making the data loader for the 3 datasets\n",
    "\n",
    "import os\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "# pytorch datasets are classes that have __init__, __len__, __getitem__ methods\n",
    "\n",
    "class Custom_DS_Big(Dataset):\n",
    "\n",
    "    def __init__(self, directory_name, transform = None):\n",
    "        self.directory = \"dataset big/\" + directory_name\n",
    "        \n",
    "        self.n_fake_imgs = 0\n",
    "        for filename in os.listdir(self.directory+ \"/Fake\"):\n",
    "            self.n_fake_imgs += 1\n",
    "        \n",
    "        self.n_real_imgs = 0\n",
    "        for filename in os.listdir(self.directory+ \"/Real\"):\n",
    "            self.n_real_imgs += 1\n",
    "\n",
    "        self.labels = torch.cat((torch.zeros(self.n_fake_imgs), torch.ones(self.n_real_imgs)))\n",
    "        # with the line above I'm making 1 indicate a real image, and zero indicates a fake image\n",
    "        # maybe it should be inverted: a 1 (or positive) should indicate a deepfake\n",
    "        # while a 0 (or false) should indicate a real image\n",
    "        # we will discuss and decide later\n",
    "        self.length = self.labels.shape[0]\n",
    "\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        label = self.labels[index]\n",
    "        if index < self.n_fake_imgs:\n",
    "            image = read_image(self.directory+ f\"/Fake/fake_{index}.jpg\")\n",
    "        else:\n",
    "            image = read_image(self.directory+ f\"/Real/real_{index-self.n_fake_imgs}.jpg\")\n",
    "        if self.transform:\n",
    "            image = to_pil_image(image)\n",
    "            image = self.transform(image)     \n",
    "        return image/256, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while the dataset class retrieves one image at the time, the dataloader class retrieves one batch of images\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_data = Custom_DS_Big(\"Train\")\n",
    "val_data = Custom_DS_Big(\"Validation\")\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment below to test the dataloaders\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# train_features, train_labels = next(iter(train_dataloader))\n",
    "# print(f\"Feature batch shape: {train_features.size()}\")\n",
    "# print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "# for i in range(train_labels.shape[0]):\n",
    "#     img = train_features[i]\n",
    "#     label = train_labels[i]\n",
    "#     plt.imshow(img.permute((1,2,0)))\n",
    "#     plt.title(f\"Label: {label}\")\n",
    "#     plt.show()\n",
    "#     if i > 4:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can now start with the actual NN\n",
    "import torch.nn as nn\n",
    "\n",
    "#defining the NN class\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, sequence):\n",
    "        super().__init__()\n",
    "        self.sequence = sequence\n",
    "    def forward(self, x):\n",
    "        pred_proba = self.sequence(x)\n",
    "        return pred_proba\n",
    "    \n",
    "#defining the functions that train and test\n",
    "\n",
    "def train_loop(model, train_data_loader, optimizer_fn, loss_fn, on_gpu = on_gpu):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch, (X,y) in enumerate(train_data_loader):\n",
    "        y = y.unsqueeze(1)\n",
    "        if on_gpu:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "        log_proba = model(X)\n",
    "        loss_value = loss_fn(log_proba, y)\n",
    "\n",
    "        loss_value.backward()\n",
    "        optimizer_fn.step()\n",
    "        optimizer_fn.zero_grad()\n",
    "        if batch % 150 == 0:\n",
    "            print(f\"Loss: {(loss_value/batch_size):.6f} | [{(batch+1) * batch_size}/{len(train_data_loader.dataset)}]\")\n",
    "\n",
    "\n",
    "def val_loop(model, val_data_loader, loss_fn, on_gpu = on_gpu):\n",
    "\n",
    "    model.eval()\n",
    "    loss, correct = 0,0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X,y in val_data_loader:\n",
    "            y = y.unsqueeze(1)\n",
    "            if on_gpu:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "            log_proba = model(X)\n",
    "            preds = log_proba > threshold\n",
    "            preds = preds.type(torch.float)\n",
    "            loss += loss_fn(log_proba, y)\n",
    "            correct += (preds == y).type(torch.float).sum().item()\n",
    "    \n",
    "    print(f\"Accuracy {(correct/len(val_data_loader.dataset)):.2%} | Loss {(loss/len(val_data_loader.dataset)):6f}\")\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to make the model\n",
    "\n",
    "first_model = NeuralNetwork(nn.Sequential(\n",
    "    nn.Conv2d(3, 64, 3, stride = 2),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(64, 16, 3, stride = 2),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Flatten(1,3),\n",
    "    nn.Linear(3600, 1000),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p_dropout),\n",
    "    nn.Linear(1000,500),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p_dropout),\n",
    "    nn.Linear(500, 1),\n",
    "    nn.Sigmoid()))\n",
    "\n",
    "if on_gpu:\n",
    "    first_model.to(device)\n",
    "\n",
    "# Binary cross entropy as loss function\n",
    "loss_function = nn.BCELoss()\n",
    "optimizer_function = torch.optim.SGD(first_model.parameters(),\n",
    "                                     lr = start_lr, momentum= momentum)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LinearLR(optimizer_function,\n",
    "                                              start_factor= start_factor, \n",
    "                                              end_factor= end_factor, \n",
    "                                              total_iters= total_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 49.81% | Loss 0.005437\n",
      "\n",
      "Epoch 1 | lr: 0.10000\n",
      "Loss: 0.005432 | [128/140002]\n",
      "Loss: 0.004715 | [19328/140002]\n",
      "Loss: 0.003963 | [38528/140002]\n",
      "Loss: 0.003925 | [57728/140002]\n",
      "Loss: 0.004549 | [76928/140002]\n",
      "Loss: 0.003976 | [96128/140002]\n",
      "Loss: 0.003865 | [115328/140002]\n",
      "Loss: 0.002807 | [134528/140002]\n",
      "Accuracy 76.43% | Loss 0.003784\n",
      "\n",
      "Epoch 2 | lr: 0.08750\n",
      "Loss: 0.003284 | [128/140002]\n",
      "Loss: 0.002866 | [19328/140002]\n",
      "Loss: 0.003044 | [38528/140002]\n",
      "Loss: 0.003219 | [57728/140002]\n",
      "Loss: 0.002381 | [76928/140002]\n",
      "Loss: 0.002731 | [96128/140002]\n",
      "Loss: 0.002593 | [115328/140002]\n",
      "Loss: 0.002335 | [134528/140002]\n",
      "Accuracy 80.70% | Loss 0.003213\n",
      "\n",
      "Epoch 3 | lr: 0.07500\n",
      "Loss: 0.002879 | [128/140002]\n",
      "Loss: 0.002252 | [19328/140002]\n",
      "Loss: 0.002566 | [38528/140002]\n",
      "Loss: 0.001999 | [57728/140002]\n",
      "Loss: 0.002574 | [76928/140002]\n",
      "Loss: 0.002120 | [96128/140002]\n",
      "Loss: 0.002038 | [115328/140002]\n",
      "Loss: 0.002283 | [134528/140002]\n",
      "Accuracy 82.08% | Loss 0.002983\n",
      "\n",
      "Epoch 4 | lr: 0.06250\n",
      "Loss: 0.001740 | [128/140002]\n",
      "Loss: 0.002146 | [19328/140002]\n",
      "Loss: 0.002725 | [38528/140002]\n",
      "Loss: 0.002031 | [57728/140002]\n",
      "Loss: 0.001405 | [76928/140002]\n",
      "Loss: 0.001818 | [96128/140002]\n",
      "Loss: 0.002147 | [115328/140002]\n",
      "Loss: 0.001424 | [134528/140002]\n",
      "Accuracy 86.47% | Loss 0.002430\n",
      "\n",
      "Epoch 5 | lr: 0.05000\n",
      "Loss: 0.001763 | [128/140002]\n",
      "Loss: 0.001458 | [19328/140002]\n",
      "Loss: 0.001500 | [38528/140002]\n",
      "Loss: 0.001608 | [57728/140002]\n",
      "Loss: 0.001909 | [76928/140002]\n",
      "Loss: 0.001578 | [96128/140002]\n",
      "Loss: 0.002032 | [115328/140002]\n",
      "Loss: 0.001822 | [134528/140002]\n",
      "Accuracy 87.01% | Loss 0.002360\n",
      "\n",
      "Epoch 6 | lr: 0.03751\n",
      "Loss: 0.000891 | [128/140002]\n",
      "Loss: 0.001046 | [19328/140002]\n",
      "Loss: 0.000748 | [38528/140002]\n",
      "Loss: 0.000755 | [57728/140002]\n",
      "Loss: 0.000929 | [76928/140002]\n",
      "Loss: 0.001381 | [96128/140002]\n",
      "Loss: 0.000962 | [115328/140002]\n",
      "Loss: 0.001786 | [134528/140002]\n",
      "Accuracy 88.46% | Loss 0.002182\n",
      "\n",
      "Epoch 7 | lr: 0.02501\n",
      "Loss: 0.000859 | [128/140002]\n",
      "Loss: 0.000788 | [19328/140002]\n",
      "Loss: 0.001508 | [38528/140002]\n",
      "Loss: 0.000742 | [57728/140002]\n",
      "Loss: 0.001184 | [76928/140002]\n",
      "Loss: 0.001274 | [96128/140002]\n",
      "Loss: 0.000357 | [115328/140002]\n",
      "Loss: 0.001561 | [134528/140002]\n",
      "Accuracy 89.12% | Loss 0.002254\n",
      "\n",
      "Epoch 8 | lr: 0.01251\n",
      "Loss: 0.001028 | [128/140002]\n",
      "Loss: 0.000710 | [19328/140002]\n",
      "Loss: 0.000539 | [38528/140002]\n",
      "Loss: 0.000504 | [57728/140002]\n",
      "Loss: 0.000549 | [76928/140002]\n",
      "Loss: 0.000864 | [96128/140002]\n",
      "Loss: 0.000642 | [115328/140002]\n",
      "Loss: 0.000443 | [134528/140002]\n",
      "Accuracy 89.35% | Loss 0.002331\n",
      "\n",
      "Epoch 9 | lr: 0.00001\n",
      "Loss: 0.000510 | [128/140002]\n",
      "Loss: 0.000362 | [19328/140002]\n",
      "Loss: 0.000282 | [38528/140002]\n",
      "Loss: 0.000407 | [57728/140002]\n",
      "Loss: 0.000490 | [76928/140002]\n",
      "Loss: 0.000529 | [96128/140002]\n",
      "Loss: 0.000381 | [115328/140002]\n",
      "Loss: 0.000235 | [134528/140002]\n",
      "Accuracy 89.25% | Loss 0.002334\n",
      "\n",
      "Epoch 10 | lr: 0.00001\n",
      "Loss: 0.000462 | [128/140002]\n",
      "Loss: 0.000612 | [19328/140002]\n",
      "Loss: 0.000483 | [38528/140002]\n",
      "Loss: 0.000619 | [57728/140002]\n",
      "Loss: 0.000714 | [76928/140002]\n",
      "Loss: 0.000808 | [96128/140002]\n",
      "Loss: 0.000427 | [115328/140002]\n",
      "Loss: 0.000368 | [134528/140002]\n",
      "Accuracy 89.24% | Loss 0.002348\n"
     ]
    }
   ],
   "source": [
    "# run this cell to train the model\n",
    "\n",
    "val_loop(first_model, val_dataloader, loss_fn= loss_function)\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    print(f\"\\nEpoch {e+1} | lr: {scheduler.get_last_lr()[0]:.5f}\")\n",
    "    train_loop(first_model, train_dataloader, optimizer_function, loss_function)\n",
    "    val_loop(first_model, val_dataloader, loss_fn= loss_function)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "total time to run the previous cell was 23 minutes 44 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(first_model, \"first_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (sequence): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 16, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Flatten(start_dim=1, end_dim=3)\n",
       "    (7): Linear(in_features=3600, out_features=1000, bias=True)\n",
       "    (8): ReLU()\n",
       "    (9): Dropout(p=0.2, inplace=False)\n",
       "    (10): Linear(in_features=1000, out_features=500, bias=True)\n",
       "    (11): ReLU()\n",
       "    (12): Dropout(p=0.2, inplace=False)\n",
       "    (13): Linear(in_features=500, out_features=1, bias=True)\n",
       "    (14): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_model = torch.load(\"first_model.pth\")\n",
    "first_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 89.24% | Loss 0.002342\n"
     ]
    }
   ],
   "source": [
    "val_loop(first_model, val_dataloader, loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'Total number of parameters: {count_parameters(first_model)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a different model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# global variables\n",
    "\n",
    "# binary classification threshold\n",
    "threshold = 0.5\n",
    "\n",
    "on_gpu = True\n",
    "\n",
    "batch_size = 128\n",
    "num_epochs = 10\n",
    "p_dropout = 0.2\n",
    "\n",
    "#SGD params\n",
    "start_lr = 1e-1\n",
    "momentum = 0.3\n",
    "\n",
    "#LR scheduler params\n",
    "start_factor= .1\n",
    "end_factor= .001 \n",
    "total_iters= 8\n",
    "\n",
    "\n",
    "if on_gpu:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Using {device} device\")\n",
    "else:\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_data = Custom_DS_Big(\"Train\")\n",
    "val_data = Custom_DS_Big(\"Validation\")\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 9286257\n"
     ]
    }
   ],
   "source": [
    "second_model = NeuralNetwork(nn.Sequential(\n",
    "    nn.Conv2d(3, 64, 3, padding = \"same\"),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(64, 64, 3, padding = \"same\"),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(64, 64, 3, padding = \"same\"),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(64, 128, 3, padding = \"same\"),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(128, 128, 3, padding = \"same\"),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(128, 128, 3, padding = \"same\"),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(128, 128, 3, padding = \"same\"),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Flatten(1,3),\n",
    "    nn.Linear(8192, 1000),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p_dropout),\n",
    "    nn.Linear(1000,500),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p_dropout),\n",
    "    nn.Linear(500, 1),\n",
    "    nn.Sigmoid()))\n",
    "\n",
    "if on_gpu:\n",
    "    second_model.to(device)\n",
    "\n",
    "print(f'Total number of parameters: {count_parameters(second_model)}')\n",
    "\n",
    "# Binary cross entropy as loss function\n",
    "loss_function = nn.BCELoss()\n",
    "optimizer_function = torch.optim.SGD(second_model.parameters(),\n",
    "                                     lr = start_lr, momentum= momentum)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LinearLR(optimizer_function,\n",
    "                                              start_factor= start_factor, \n",
    "                                              end_factor= end_factor, \n",
    "                                              total_iters= total_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 | lr: 0.01000\n",
      "Loss: 0.005416 | [128/140002]\n",
      "Loss: 0.005406 | [19328/140002]\n",
      "Loss: 0.005421 | [38528/140002]\n",
      "Loss: 0.005417 | [57728/140002]\n",
      "Loss: 0.005415 | [76928/140002]\n",
      "Loss: 0.005417 | [96128/140002]\n",
      "Loss: 0.005418 | [115328/140002]\n",
      "Loss: 0.005416 | [134528/140002]\n",
      "Accuracy 50.19% | Loss 0.005432\n",
      "\n",
      "Epoch 2 | lr: 0.00876\n",
      "Loss: 0.005410 | [128/140002]\n",
      "Loss: 0.005419 | [19328/140002]\n",
      "Loss: 0.005412 | [38528/140002]\n",
      "Loss: 0.005415 | [57728/140002]\n",
      "Loss: 0.005416 | [76928/140002]\n",
      "Loss: 0.005416 | [96128/140002]\n",
      "Loss: 0.005417 | [115328/140002]\n",
      "Loss: 0.005417 | [134528/140002]\n",
      "Accuracy 49.81% | Loss 0.005432\n",
      "\n",
      "Epoch 3 | lr: 0.00753\n",
      "Loss: 0.005415 | [128/140002]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | lr: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscheduler\u001b[38;5;241m.\u001b[39mget_last_lr()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m     train_loop(second_model, train_dataloader, optimizer_function, loss_function)\n\u001b[0;32m      6\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(second_model, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msecond_model_epoch_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m     val_loop(second_model, val_dataloader, loss_fn\u001b[38;5;241m=\u001b[39m loss_function)\n",
      "Cell \u001b[1;32mIn[4], line 22\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(model, train_data_loader, optimizer_fn, loss_fn, on_gpu)\u001b[0m\n\u001b[0;32m     20\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_gpu:\n\u001b[1;32m---> 22\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     24\u001b[0m log_proba \u001b[38;5;241m=\u001b[39m model(X)\n\u001b[0;32m     25\u001b[0m loss_value \u001b[38;5;241m=\u001b[39m loss_fn(log_proba, y)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# val_loop(second_model, val_dataloader, loss_fn= loss_function)\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    print(f\"\\nEpoch {e+1} | lr: {scheduler.get_last_lr()[0]:.5f}\")\n",
    "    train_loop(second_model, train_dataloader, optimizer_function, loss_function)\n",
    "    torch.save(second_model, f\"second_model_epoch_{e+1}.pth\")\n",
    "    val_loop(second_model, val_dataloader, loss_fn= loss_function)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(second_model, \"second_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
