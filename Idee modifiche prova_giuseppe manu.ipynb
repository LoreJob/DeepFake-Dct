{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will try to make a network that classifies images as fake or real.\n",
    "\n",
    "I will use pytorch because it's the library that I have the most experience with.\n",
    "\n",
    "The train / validation / test split I will use is the one already present in the repo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# global variables\n",
    "\n",
    "# binary classification threshold\n",
    "threshold = 0.5\n",
    "\n",
    "on_gpu = True\n",
    "\n",
    "batch_size = 256\n",
    "num_epochs = 10\n",
    "p_dropout = 0.2\n",
    "\n",
    "#SGD params\n",
    "start_lr = 1e-1\n",
    "momentum = 0.3\n",
    "\n",
    "#LR scheduler params\n",
    "start_factor= 1\n",
    "end_factor= .0001 \n",
    "total_iters= 8\n",
    "\n",
    "\n",
    "if on_gpu:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Using {device} device\")\n",
    "else:\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE I ADDED THE TRANSFORM IN THE __INIT__ and in the __GETITEM__\n",
    "\n",
    "# I will start by making the data loader for the 3 datasets\n",
    "\n",
    "import os\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "# pytorch datasets are classes that have __init__, __len__, __getitem__ methods\n",
    "\n",
    "class Custom_DS_Big(Dataset):\n",
    "\n",
    "    def __init__(self, directory_name, transform = None):\n",
    "        self.directory = \"dataset big/\" + directory_name\n",
    "        \n",
    "        self.n_fake_imgs = 0\n",
    "        for filename in os.listdir(self.directory+ \"/Fake\"):\n",
    "            self.n_fake_imgs += 1\n",
    "        \n",
    "        self.n_real_imgs = 0\n",
    "        for filename in os.listdir(self.directory+ \"/Real\"):\n",
    "            self.n_real_imgs += 1\n",
    "\n",
    "        self.labels = torch.cat((torch.zeros(self.n_fake_imgs), torch.ones(self.n_real_imgs)))\n",
    "        # with the line above I'm making 1 indicate a real image, and zero indicates a fake image\n",
    "        # maybe it should be inverted: a 1 (or positive) should indicate a deepfake\n",
    "        # while a 0 (or false) should indicate a real image\n",
    "        # we will discuss and decide later\n",
    "        self.length = self.labels.shape[0]\n",
    "\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        label = self.labels[index]\n",
    "        if index < self.n_fake_imgs:\n",
    "            image = read_image(self.directory+ f\"/Fake/fake_{index}.jpg\")\n",
    "        else:\n",
    "            image = read_image(self.directory+ f\"/Real/real_{index-self.n_fake_imgs}.jpg\")\n",
    "        if self.transform:\n",
    "            image = to_pil_image(image)\n",
    "            image = self.transform(image)     \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THATS NEW!\n",
    "\n",
    "# creating a data augmentation technique to make the model more robust to variations in the data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE I ADDED THE TRANSFORM FUNCTION\n",
    "\n",
    "# while the dataset class retrieves one image at the time, the dataloader class retrieves one batch of images\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_data = Custom_DS_Big(\"Train\", transform = transform)\n",
    "val_data = Custom_DS_Big(\"Validation\", transform = transform)\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment below to test the dataloaders\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# train_features, train_labels = next(iter(train_dataloader))\n",
    "# print(f\"Feature batch shape: {train_features.size()}\")\n",
    "# print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "# for i in range(train_labels.shape[0]):\n",
    "#     img = train_features[i]\n",
    "#     label = train_labels[i]\n",
    "#     plt.imshow(img.permute((1,2,0)))\n",
    "#     plt.title(f\"Label: {label}\")\n",
    "#     plt.show()\n",
    "#     if i > 4:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can now start with the actual NN\n",
    "import torch.nn as nn\n",
    "\n",
    "#defining the NN class\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, sequence):\n",
    "        super().__init__()\n",
    "        self.sequence = sequence\n",
    "    def forward(self, x):\n",
    "        pred_proba = self.sequence(x)\n",
    "        return pred_proba\n",
    "    \n",
    "#defining the functions that train and test\n",
    "\n",
    "def train_loop(model, train_data_loader, optimizer_fn, loss_fn, on_gpu = on_gpu):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch, (X,y) in enumerate(train_data_loader):\n",
    "        y = y.unsqueeze(1)\n",
    "        if on_gpu:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "        log_proba = model(X)\n",
    "        loss_value = loss_fn(log_proba, y)\n",
    "\n",
    "        loss_value.backward()\n",
    "        optimizer_fn.step()\n",
    "        optimizer_fn.zero_grad()\n",
    "        if batch % 150 == 0:\n",
    "            print(f\"Loss: {(loss_value/batch_size):.6f} | [{(batch+1) * batch_size}/{len(train_data_loader.dataset)}]\")\n",
    "\n",
    "\n",
    "def val_loop(model, val_data_loader, loss_fn, on_gpu = on_gpu):\n",
    "\n",
    "    model.eval()\n",
    "    loss, correct = 0,0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X,y in val_data_loader:\n",
    "            y = y.unsqueeze(1)\n",
    "            if on_gpu:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "            log_proba = model(X)\n",
    "            preds = log_proba > threshold\n",
    "            preds = preds.type(torch.float)\n",
    "            loss += loss_fn(log_proba, y)\n",
    "            correct += (preds == y).type(torch.float).sum().item()\n",
    "    \n",
    "    print(f\"Accuracy {(correct/len(val_data_loader.dataset)):.2%} | Loss {(loss/len(val_data_loader.dataset)):6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE I MODIFIED THE NN ADDING A NORMALIZATION LAYER AND ONE MORE CONVOLUTIONAL LAYER. I ALSO ADDED THAT THE SECOND DROP OUT IS DROPPING MORE THINGS AND I CHANGED SOME PARAMETERS\n",
    "\n",
    "# run this cell to make the model\n",
    "\n",
    "first_model = NeuralNetwork(nn.Sequential(\n",
    "    nn.Conv2d(3, 64, 3, stride = 2),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(64, 128, 3, stride=2),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(128, 256, 3, stride = 2),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(2304, 1000),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p_dropout),\n",
    "    nn.Linear(1000, 500),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p_dropout+0.2),\n",
    "    nn.Linear(500, 1),\n",
    "    nn.Sigmoid()\n",
    "    ))\n",
    "\n",
    "if on_gpu:\n",
    "    first_model.to(device)\n",
    "\n",
    "# Binary cross entropy as loss function\n",
    "loss_function = nn.BCELoss()\n",
    "optimizer_function = torch.optim.SGD(first_model.parameters(),\n",
    "                                     lr = start_lr, momentum= momentum)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LinearLR(optimizer_function,\n",
    "                                              start_factor= start_factor, \n",
    "                                              end_factor= end_factor, \n",
    "                                              total_iters= total_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 | lr: 0.10000\n",
      "Loss: 0.002706 | [256/140002]\n",
      "Loss: 0.002386 | [38656/140002]\n",
      "Loss: 0.001915 | [77056/140002]\n",
      "Loss: 0.001592 | [115456/140002]\n",
      "Accuracy 78.77% | Loss 0.001752\n",
      "\n",
      "Epoch 2 | lr: 0.08750\n",
      "Loss: 0.001739 | [256/140002]\n",
      "Loss: 0.001266 | [38656/140002]\n",
      "Loss: 0.000882 | [77056/140002]\n",
      "Loss: 0.000996 | [115456/140002]\n",
      "Accuracy 80.96% | Loss 0.001697\n",
      "\n",
      "Epoch 3 | lr: 0.07500\n",
      "Loss: 0.001040 | [256/140002]\n",
      "Loss: 0.000659 | [38656/140002]\n",
      "Loss: 0.000938 | [77056/140002]\n",
      "Loss: 0.000967 | [115456/140002]\n",
      "Accuracy 87.56% | Loss 0.001104\n",
      "\n",
      "Epoch 4 | lr: 0.06250\n",
      "Loss: 0.000801 | [256/140002]\n",
      "Loss: 0.000787 | [38656/140002]\n",
      "Loss: 0.000743 | [77056/140002]\n",
      "Loss: 0.000641 | [115456/140002]\n",
      "Accuracy 88.80% | Loss 0.001009\n",
      "\n",
      "Epoch 5 | lr: 0.05000\n",
      "Loss: 0.000456 | [256/140002]\n",
      "Loss: 0.000683 | [38656/140002]\n",
      "Loss: 0.000537 | [77056/140002]\n",
      "Loss: 0.000667 | [115456/140002]\n",
      "Accuracy 90.58% | Loss 0.000893\n",
      "\n",
      "Epoch 6 | lr: 0.03751\n",
      "Loss: 0.000413 | [256/140002]\n",
      "Loss: 0.000523 | [38656/140002]\n",
      "Loss: 0.000602 | [77056/140002]\n",
      "Loss: 0.000424 | [115456/140002]\n",
      "Accuracy 90.03% | Loss 0.000927\n",
      "\n",
      "Epoch 7 | lr: 0.02501\n",
      "Loss: 0.000459 | [256/140002]\n",
      "Loss: 0.000622 | [38656/140002]\n",
      "Loss: 0.000466 | [77056/140002]\n",
      "Loss: 0.000399 | [115456/140002]\n",
      "Accuracy 92.07% | Loss 0.000754\n",
      "\n",
      "Epoch 8 | lr: 0.01251\n",
      "Loss: 0.000402 | [256/140002]\n",
      "Loss: 0.000297 | [38656/140002]\n",
      "Loss: 0.000426 | [77056/140002]\n",
      "Loss: 0.000532 | [115456/140002]\n",
      "Accuracy 91.42% | Loss 0.000849\n",
      "\n",
      "Epoch 9 | lr: 0.00001\n",
      "Loss: 0.000271 | [256/140002]\n",
      "Loss: 0.000335 | [38656/140002]\n",
      "Loss: 0.000622 | [77056/140002]\n",
      "Loss: 0.000472 | [115456/140002]\n",
      "Accuracy 91.68% | Loss 0.000815\n",
      "\n",
      "Epoch 10 | lr: 0.00001\n",
      "Loss: 0.000420 | [256/140002]\n",
      "Loss: 0.000399 | [38656/140002]\n",
      "Loss: 0.000668 | [77056/140002]\n",
      "Loss: 0.000360 | [115456/140002]\n",
      "Accuracy 91.86% | Loss 0.000794\n"
     ]
    }
   ],
   "source": [
    "# run this cell to train the model\n",
    "\n",
    "# val_loop(first_model, val_dataloader, loss_fn= loss_function)\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    print(f\"\\nEpoch {e+1} | lr: {scheduler.get_last_lr()[0]:.5f}\")\n",
    "    train_loop(first_model, train_dataloader, optimizer_function, loss_function)\n",
    "    val_loop(first_model, val_dataloader, loss_fn= loss_function)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "total time to run the previous cell was 226 minutes 32 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(first_model, \"manuel_mods.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (sequence): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (5): ReLU()\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (8): ReLU()\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Flatten(start_dim=1, end_dim=-1)\n",
       "    (11): Linear(in_features=2304, out_features=1000, bias=True)\n",
       "    (12): ReLU()\n",
       "    (13): Dropout(p=0.2, inplace=False)\n",
       "    (14): Linear(in_features=1000, out_features=500, bias=True)\n",
       "    (15): ReLU()\n",
       "    (16): Dropout(p=0.4, inplace=False)\n",
       "    (17): Linear(in_features=500, out_features=1, bias=True)\n",
       "    (18): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_model = torch.load(\"manuel_mods.pth\")\n",
    "first_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 91.62% | Loss 0.000802\n"
     ]
    }
   ],
   "source": [
    "val_loop(first_model, val_dataloader, loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 3176945\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'Total number of parameters: {count_parameters(first_model)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
