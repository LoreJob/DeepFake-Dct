{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing speed difference between loading to cpu and gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time in microseconds: 133.4\n",
      "torch.Size([10, 64, 64, 3])\n"
     ]
    }
   ],
   "source": [
    "from time import perf_counter_ns\n",
    "\n",
    "processed_video = np.load(\"..\\\\processed_data_10_frames\\\\Val\\\\fake\\\\1(smile).npy\")\n",
    "\n",
    "# device = \"cuda\"\n",
    "device = \"cpu\"\n",
    "\n",
    "start = perf_counter_ns()\n",
    "video = torch.from_numpy(processed_video).to(device)\n",
    "torch.cuda.synchronize()\n",
    "end = perf_counter_ns()\n",
    "\n",
    "print(f\"total time in microseconds: {(end-start)/1000}\")\n",
    "print(video.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining base dataset class for videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want the dataset class to construct the batches, instead of the data loader object.\n",
    "\n",
    "\n",
    "class VideoDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, processed_dir = \"../Processed_data\", subset = \"Train\", batch_size = 32, device = \"cuda\"):\n",
    "        self.directory = processed_dir+\"/\"+subset\n",
    "        self.batch_size = batch_size\n",
    "        self.subset = subset\n",
    "        self.device = device\n",
    "\n",
    "        self.videos = self._get_video_paths()\n",
    "        self._shuffle_data()\n",
    "\n",
    "        self.length = int(len(self.videos)/self.batch_size) + 1\n",
    "    \n",
    "    def _get_video_paths(self):\n",
    "        videos = []\n",
    "        for filename in os.listdir(self.directory + \"/real\"):\n",
    "            if filename.endswith(\".npy\"):\n",
    "                videos.append((self.directory + \"/real/\"+ filename,0))\n",
    "        for filename in os.listdir(self.directory + \"/fake\"):\n",
    "            if filename.endswith(\".npy\"):\n",
    "                videos.append((self.directory + \"/fake/\"+ filename,1))\n",
    "        return videos\n",
    "    \n",
    "    def _shuffle_data(self):\n",
    "        np.random.shuffle(self.videos)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        #this function will return an array of the following shape:\n",
    "        #(batch_size, n_frames, height, width, n_channels)\n",
    "        # and a vector of length batch_size that indicates the \n",
    "        # class: 0 for real videos, 1 for fake videos\n",
    "        features = []\n",
    "        targets = []\n",
    "        for video_path, label in self.videos[index*self.batch_size:(index+1)*self.batch_size]:\n",
    "            array = torch.from_numpy(np.load(video_path)).to(self.device)\n",
    "            features.append(array)\n",
    "            targets.append(label)\n",
    "        return torch.stack(features), torch.tensor(targets).to(self.device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the speed of the data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = VideoDataset(processed_dir= \"..\\\\Processed_Data\", subset= \"Val\", batch_size= 128, device = \"cuda\")\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size= None, collate_fn= lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type is <class 'torch.Tensor'>, the lenght is 56\n",
      "torch.Size([56, 20, 64, 64, 3])\n",
      "Time elapsed was 3.7737520000664517\n"
     ]
    }
   ],
   "source": [
    "from time import perf_counter\n",
    "\n",
    "start = perf_counter()\n",
    "for i,thing in enumerate(val_dataloader):\n",
    "    if i == 23:\n",
    "        print(f\"The type is {type(thing[0])}, the lenght is {len(thing[0])}\")\n",
    "        print(thing[0].shape)\n",
    "        break\n",
    "torch.cuda.synchronize()\n",
    "end = perf_counter()\n",
    "print(f\"Time elapsed was {end-start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the testing I am doing it looks like this dataloader has roughly the same speed as the one we use with tensorflow. I tested videos with 10, 20, 40 frames and batch sizes of 32 and 128 videos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first I have to make the Time distributed class, that applies the same CNN to each temporal slice of the input\n",
    "\n",
    "#this code is provided by chatGPT, I have to modify it and test it\n",
    "\n",
    "class TimeDistributed(nn.Module):\n",
    "    def __init__(self, layer):\n",
    "        super(TimeDistributed, self).__init__()\n",
    "        self.layer = layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        #  x is of shape (batch_size, n_frames, height, width, n_channels)\n",
    "        batch_size, n_frames, height, width, n_channels = x.size()\n",
    "        \n",
    "         # Reshape input to (batch_size * n_frames, n_channels, height, width)\n",
    "        x = x.view(batch_size * n_frames, n_channels, height, width)\n",
    "        \n",
    "        # Apply the layer to the reshaped tensor\n",
    "        y = self.layer(x)\n",
    "        \n",
    "        # Get output dimensions\n",
    "        output_dim = y.size(1)\n",
    "        new_height = y.size(2)\n",
    "        new_width = y.size(3)\n",
    "        \n",
    "        # Reshape the output back to (batch_size, n_frames, output_dim, new_height, new_width)\n",
    "        y = y.view(batch_size, n_frames, output_dim, new_height, new_width)\n",
    "        \n",
    "        return y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
