{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the CNN\n",
    "\n",
    "I will train a cnn on the images of the folder Dataset, this resulting CNN will be applied to each frame of a video and will return an embedding for each frame. This will be fed into a LSTM to classify the video as either real or fake\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image preprocessing and data loaders\n",
    "\n",
    "the images in the Dataset folder are 256x256 pixels, but the videos we are classifying with the LSTM will be preprocessed to be 64x64. For this reason, the CNN as well will be trained on images 64x64. The following code will resize the dataset and prepare the dataloader object to train the CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Train real: 100%|██████████| 70001/70001 [03:19<00:00, 351.50it/s]\n",
      "Processing Train fake: 100%|██████████| 70001/70001 [03:22<00:00, 344.97it/s]\n",
      "Processing Validation real: 100%|██████████| 19787/19787 [00:54<00:00, 365.66it/s]\n",
      "Processing Validation fake: 100%|██████████| 19641/19641 [00:53<00:00, 366.82it/s]\n",
      "Processing Test real: 100%|██████████| 5413/5413 [00:14<00:00, 366.39it/s]\n",
      "Processing Test fake: 100%|██████████| 5492/5492 [00:15<00:00, 355.21it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms.functional import resize\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def resize_image(img_path):\n",
    "    img = read_image(img_path)\n",
    "    return resize(img, size = [64,64])\n",
    "\n",
    "# testing the function\n",
    "# import matplotlib.pyplot as plt\n",
    "# before = read_image(\"Dataset/Validation/fake/fake_0.jpg\")\n",
    "# after = resize_image(\"Dataset/Validation/fake/fake_0.jpg\")\n",
    "# fig, axes = plt.subplots(nrows= 1, ncols= 2)\n",
    "# axes = axes.flatten()\n",
    "# axes[0].imshow(before.permute(1,2,0))\n",
    "# axes[1].imshow(after.permute(1,2,0))\n",
    "\n",
    "def resize_dataset(output_dir):\n",
    "    for subset in ['Train', 'Validation', 'Test']:\n",
    "        for class_name in ['real', 'fake']:\n",
    "            input_dir = os.path.join(\"Dataset\", subset, class_name)\n",
    "            new_output_dir = os.path.join(output_dir, subset, class_name)\n",
    "            os.makedirs(new_output_dir, exist_ok=True)\n",
    "            \n",
    "            img_files = [f for f in os.listdir(input_dir) if f.endswith('.jpg')]\n",
    "            \n",
    "            for img_file in tqdm(img_files, desc=f\"Processing {subset} {class_name}\"):\n",
    "                video_path = os.path.join(input_dir, img_file)\n",
    "                processed_image = resize_image(video_path)\n",
    "                \n",
    "                output_path = os.path.join(new_output_dir, img_file.replace('.jpg', '.pth'))\n",
    "                torch.save(processed_image, output_path)\n",
    "\n",
    "# resize_dataset(\"..\\\\resized_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "\n",
    "    def __init__(self, processed_dir = \"../resized_images\", subset = \"Train\"):\n",
    "        self.directory = processed_dir+\"/\"+subset\n",
    "        self.images = self._get_img_paths()\n",
    "        self._shuffle_data()\n",
    "    \n",
    "    def _get_img_paths(self):\n",
    "        imgs = []\n",
    "        for img_path in os.listdir(self.directory + \"/Fake\"):\n",
    "            imgs.append((self.directory + \"/Fake/\"+img_path, 1))\n",
    "        for img_path in os.listdir(self.directory + \"/Real\"):\n",
    "            imgs.append((self.directory + \"/Real/\"+img_path, 0))\n",
    "        return imgs\n",
    "    \n",
    "    def _shuffle_data(self):\n",
    "        np.random.shuffle(self.images)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        features, target = self.images[index]\n",
    "        return torch.load(features), target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "\n",
    "val_img_dataset = ImageDataset(subset=\"Validation\")\n",
    "\n",
    "val_img_loader = DataLoader(val_img_dataset, batch_size= 64, shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 64, 64]) is the shape of x\n",
      "torch.Size([64]) is the shape of y\n"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(val_img_loader))\n",
    "print(f\"{x.shape} is the shape of x\\n{y.shape} is the shape of y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
